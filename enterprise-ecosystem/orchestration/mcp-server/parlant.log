[2m2025-08-18T02:38:31.881539Z[0m [[32m[1minfo     [0m] [1m[<main>] Parlant server version 3.0.1[0m
[2m2025-08-18T02:38:31.883563Z[0m [[32m[1minfo     [0m] [1m[<main>] Using home directory 'C:\Users\usuario\parlant-data'[0m
[2m2025-08-18T02:38:31.889000Z[0m [[32m[1minfo     [0m] [1m[<main>] No external modules selected[0m
[2m2025-08-18T02:38:33.176328Z[0m [[32m[1minfo     [0m] [1m[<main>] Initialized OpenAIService[0m
[2m2025-08-18T04:43:43.252029Z[0m [[32m[1minfo     [0m] [1m[<main>] Parlant server version 3.0.1[0m
[2m2025-08-18T04:43:43.253433Z[0m [[32m[1minfo     [0m] [1m[<main>] Using home directory 'C:\Users\usuario\parlant-data'[0m
[2m2025-08-18T04:43:43.259673Z[0m [[32m[1minfo     [0m] [1m[<main>] No external modules selected[0m
[2m2025-08-18T04:43:44.606250Z[0m [[32m[1minfo     [0m] [1m[<main>] Initialized OpenAIService[0m
[2m2025-08-18T04:44:11.193168Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] LLM Request (GuidelineContinuousPropositionSchema) failed[0m
[2m2025-08-18T04:44:11.198575Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] Traceback (most recent call last):
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 275, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 411, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 137, in generate
    return await self._do_generate(prompt, hints)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 193, in _do_generate
    response = await self._client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2454, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
    ...<45 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1791, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1591, in request
    raise self._make_status_error_from_response(err.response) from None
 openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32
[0m
[2m2025-08-18T04:44:11.264436Z[0m [[33m[1mwarning  [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] GuidelineContinuousProposer attempt 0 failed: ['Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 69, in propose_continuous\n    proposition = await self._generate_continuous(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        guideline, temperature=generation_attempt_temperatures[generation_attempt]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 179, in _generate_continuous\n    response = await self._schematic_generator.generate(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 135, in wrapped_func\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 125, in wrapped_func\n    return await func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 137, in generate\n    return await self._do_generate(prompt, hints)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 193, in _do_generate\n    response = await self._client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1791, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1591, in request\n    raise self._make_status_error_from_response(err.response) from None\n', 'openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32\n'][0m
[2m2025-08-18T04:44:11.918421Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] LLM Request (GuidelineContinuousPropositionSchema) failed[0m
[2m2025-08-18T04:44:11.923485Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] Traceback (most recent call last):
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 275, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 411, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 137, in generate
    return await self._do_generate(prompt, hints)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 193, in _do_generate
    response = await self._client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2454, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
    ...<45 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1791, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1591, in request
    raise self._make_status_error_from_response(err.response) from None
 openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32
[0m
[2m2025-08-18T04:44:11.932071Z[0m [[33m[1mwarning  [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] GuidelineContinuousProposer attempt 1 failed: ['Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 69, in propose_continuous\n    proposition = await self._generate_continuous(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        guideline, temperature=generation_attempt_temperatures[generation_attempt]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 179, in _generate_continuous\n    response = await self._schematic_generator.generate(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 135, in wrapped_func\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 125, in wrapped_func\n    return await func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 137, in generate\n    return await self._do_generate(prompt, hints)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 193, in _do_generate\n    response = await self._client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1791, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1591, in request\n    raise self._make_status_error_from_response(err.response) from None\n', 'openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32\n'][0m
[2m2025-08-18T04:44:12.214474Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] LLM Request (GuidelineContinuousPropositionSchema) failed[0m
[2m2025-08-18T04:44:12.218803Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] Traceback (most recent call last):
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 275, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 411, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 137, in generate
    return await self._do_generate(prompt, hints)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 193, in _do_generate
    response = await self._client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2454, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
    ...<45 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1791, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1591, in request
    raise self._make_status_error_from_response(err.response) from None
 openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32
[0m
[2m2025-08-18T04:44:12.227976Z[0m [[33m[1mwarning  [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] GuidelineContinuousProposer attempt 2 failed: ['Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 69, in propose_continuous\n    proposition = await self._generate_continuous(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        guideline, temperature=generation_attempt_temperatures[generation_attempt]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 179, in _generate_continuous\n    response = await self._schematic_generator.generate(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 135, in wrapped_func\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 125, in wrapped_func\n    return await func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 137, in generate\n    return await self._do_generate(prompt, hints)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 193, in _do_generate\n    response = await self._client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1791, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1591, in request\n    raise self._make_status_error_from_response(err.response) from None\n', 'openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32\n'][0m
[2m2025-08-18T04:44:12.229692Z[0m [[32m[1minfo     [0m] [1m[<main>] Evaluation task 'kI6TkyuQz4' failed due to the following error: 'Evaluation failed'[0m
[2m2025-08-18T04:44:12.428441Z[0m [[32m[1minfo     [0m] [1m[<main>] BackgroundTaskService: Cancelling all remaining tasks (2)[0m
[2m2025-08-18T04:44:12.428818Z[0m [[32m[1minfo     [0m] [1m[<main>] BackgroundTaskService: Shutting down[0m
[2m2025-08-18T04:44:12.459677Z[0m [[33m[1mwarning  [0m] [1m[<main>] BackgroundTaskService: Awaited task raised an exception: ['Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 69, in propose_continuous\n    proposition = await self._generate_continuous(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        guideline, temperature=generation_attempt_temperatures[generation_attempt]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 179, in _generate_continuous\n    response = await self._schematic_generator.generate(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 135, in wrapped_func\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 125, in wrapped_func\n    return await func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 137, in generate\n    return await self._do_generate(prompt, hints)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 193, in _do_generate\n    response = await self._client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1791, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1591, in request\n    raise self._make_status_error_from_response(err.response) from None\n', 'openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32\n', '\nThe above exception was the direct cause of the following exception:\n\n', 'Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\background_tasks.py", line 130, in _await_task\n    await task\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\behavioral_change_evaluation.py", line 1021, in _run_evaluation\n    guideline_evaluation_data, journey_evaluation_data = await async_utils.safe_gather(\n                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<16 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\async_utils.py", line 148, in safe_gather\n    return await asyncio.gather(\n           ^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\behavioral_change_evaluation.py", line 746, in evaluate\n    continuous_propositions = await self._propose_continuous(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\behavioral_change_evaluation.py", line 864, in _propose_continuous\n    sparse_results = await async_utils.safe_gather(*tasks)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\async_utils.py", line 148, in safe_gather\n    return await asyncio.gather(\n           ^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 86, in propose_continuous\n    raise EvaluationError() from last_generation_exception\n', 'parlant.core.services.indexing.common.EvaluationError: Evaluation failed\n'][0m
[2m2025-08-18T04:45:47.001348Z[0m [[32m[1minfo     [0m] [1m[<main>] Parlant server version 3.0.1[0m
[2m2025-08-18T04:45:47.002291Z[0m [[32m[1minfo     [0m] [1m[<main>] Using home directory 'C:\Users\usuario\parlant-data'[0m
[2m2025-08-18T04:45:47.008690Z[0m [[32m[1minfo     [0m] [1m[<main>] No external modules selected[0m
[2m2025-08-18T04:45:48.045408Z[0m [[32m[1minfo     [0m] [1m[<main>] Initialized OpenAIService[0m
[2m2025-08-18T04:48:09.757962Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] LLM Request (GuidelineContinuousPropositionSchema) failed[0m
[2m2025-08-18T04:48:09.761940Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] Traceback (most recent call last):
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 275, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 411, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 137, in generate
    return await self._do_generate(prompt, hints)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 193, in _do_generate
    response = await self._client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2454, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
    ...<45 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1791, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1591, in request
    raise self._make_status_error_from_response(err.response) from None
 openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32
[0m
[2m2025-08-18T04:48:09.776271Z[0m [[33m[1mwarning  [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] GuidelineContinuousProposer attempt 0 failed: ['Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 69, in propose_continuous\n    proposition = await self._generate_continuous(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        guideline, temperature=generation_attempt_temperatures[generation_attempt]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 179, in _generate_continuous\n    response = await self._schematic_generator.generate(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 135, in wrapped_func\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 125, in wrapped_func\n    return await func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 137, in generate\n    return await self._do_generate(prompt, hints)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 193, in _do_generate\n    response = await self._client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1791, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1591, in request\n    raise self._make_status_error_from_response(err.response) from None\n', 'openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32\n'][0m
[2m2025-08-18T04:48:10.043829Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] LLM Request (GuidelineContinuousPropositionSchema) failed[0m
[2m2025-08-18T04:48:10.047462Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] Traceback (most recent call last):
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 275, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 411, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 137, in generate
    return await self._do_generate(prompt, hints)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 193, in _do_generate
    response = await self._client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2454, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
    ...<45 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1791, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1591, in request
    raise self._make_status_error_from_response(err.response) from None
 openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32
[0m
[2m2025-08-18T04:48:10.052424Z[0m [[33m[1mwarning  [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] GuidelineContinuousProposer attempt 1 failed: ['Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 69, in propose_continuous\n    proposition = await self._generate_continuous(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        guideline, temperature=generation_attempt_temperatures[generation_attempt]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 179, in _generate_continuous\n    response = await self._schematic_generator.generate(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 135, in wrapped_func\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 125, in wrapped_func\n    return await func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 137, in generate\n    return await self._do_generate(prompt, hints)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 193, in _do_generate\n    response = await self._client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1791, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1591, in request\n    raise self._make_status_error_from_response(err.response) from None\n', 'openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32\n'][0m
[2m2025-08-18T04:48:10.342860Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] LLM Request (GuidelineContinuousPropositionSchema) failed[0m
[2m2025-08-18T04:48:10.347611Z[0m [[31m[1merror    [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] Traceback (most recent call last):
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 275, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\core\loggers.py", line 411, in operation
    yield
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 137, in generate
    return await self._do_generate(prompt, hints)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\parlant\adapters\nlp\openai_service.py", line 193, in _do_generate
    response = await self._client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2454, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
    ...<45 lines>...
    )
    ^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1791, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   File "C:\Users\usuario\scoop\apps\miniconda3\current\Lib\site-packages\openai\_base_client.py", line 1591, in request
    raise self._make_status_error_from_response(err.response) from None
 openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32
[0m
[2m2025-08-18T04:48:10.355996Z[0m [[33m[1mwarning  [0m] [1m[<main>][GuidelineContinuousProposer][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)][OpenAISchematicGenerator][LLM Request (GuidelineContinuousPropositionSchema)] GuidelineContinuousProposer attempt 2 failed: ['Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 69, in propose_continuous\n    proposition = await self._generate_continuous(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        guideline, temperature=generation_attempt_temperatures[generation_attempt]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 179, in _generate_continuous\n    response = await self._schematic_generator.generate(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 135, in wrapped_func\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 125, in wrapped_func\n    return await func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 137, in generate\n    return await self._do_generate(prompt, hints)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 193, in _do_generate\n    response = await self._client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1791, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1591, in request\n    raise self._make_status_error_from_response(err.response) from None\n', 'openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32\n'][0m
[2m2025-08-18T04:48:10.357177Z[0m [[32m[1minfo     [0m] [1m[<main>] Evaluation task 'nqCRo8SAmo' failed due to the following error: 'Evaluation failed'[0m
[2m2025-08-18T04:48:10.834145Z[0m [[32m[1minfo     [0m] [1m[<main>] BackgroundTaskService: Cancelling all remaining tasks (2)[0m
[2m2025-08-18T04:48:10.834604Z[0m [[32m[1minfo     [0m] [1m[<main>] BackgroundTaskService: Shutting down[0m
[2m2025-08-18T04:48:10.842243Z[0m [[33m[1mwarning  [0m] [1m[<main>] BackgroundTaskService: Awaited task raised an exception: ['Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 69, in propose_continuous\n    proposition = await self._generate_continuous(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        guideline, temperature=generation_attempt_temperatures[generation_attempt]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 179, in _generate_continuous\n    response = await self._schematic_generator.generate(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 135, in wrapped_func\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 144, in wrapped_func\n    return await policy.apply(state, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 60, in apply\n    return await func(state, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\nlp\\policies.py", line 125, in wrapped_func\n    return await func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 137, in generate\n    return await self._do_generate(prompt, hints)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\adapters\\nlp\\openai_service.py", line 193, in _do_generate\n    response = await self._client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1791, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\openai\\_base_client.py", line 1591, in request\n    raise self._make_status_error_from_response(err.response) from None\n', 'openai.UnprocessableEntityError: Failed to deserialize the JSON body into the target type: messages[0].role: unknown variant `developer`, expected one of `system`, `user`, `assistant`, `tool`, `function` at line 1 column 32\n', '\nThe above exception was the direct cause of the following exception:\n\n', 'Traceback (most recent call last):\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\background_tasks.py", line 130, in _await_task\n    await task\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\behavioral_change_evaluation.py", line 1021, in _run_evaluation\n    guideline_evaluation_data, journey_evaluation_data = await async_utils.safe_gather(\n                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<16 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\async_utils.py", line 148, in safe_gather\n    return await asyncio.gather(\n           ^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\behavioral_change_evaluation.py", line 746, in evaluate\n    continuous_propositions = await self._propose_continuous(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\behavioral_change_evaluation.py", line 864, in _propose_continuous\n    sparse_results = await async_utils.safe_gather(*tasks)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\async_utils.py", line 148, in safe_gather\n    return await asyncio.gather(\n           ^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n    )\n    ^\n', '  File "C:\\Users\\usuario\\scoop\\apps\\miniconda3\\current\\Lib\\site-packages\\parlant\\core\\services\\indexing\\guideline_continuous_proposer.py", line 86, in propose_continuous\n    raise EvaluationError() from last_generation_exception\n', 'parlant.core.services.indexing.common.EvaluationError: Evaluation failed\n'][0m
[2m2025-08-18T04:50:00.402375Z[0m [[32m[1minfo     [0m] [1m[<main>] Parlant server version 3.0.1[0m
[2m2025-08-18T04:50:00.402962Z[0m [[32m[1minfo     [0m] [1m[<main>] Using home directory 'C:\Users\usuario\parlant-data'[0m
[2m2025-08-18T04:50:00.407916Z[0m [[32m[1minfo     [0m] [1m[<main>] No external modules selected[0m
[2m2025-08-18T04:50:01.038194Z[0m [[32m[1minfo     [0m] [1m[<main>] Initialized OpenAIService[0m
[2m2025-08-18T04:53:33.112340Z[0m [[32m[1minfo     [0m] [1m[<main>] BackgroundTaskService: Cancelling all remaining tasks (1)[0m
[2m2025-08-18T04:53:33.157937Z[0m [[32m[1minfo     [0m] [1m[<main>] BackgroundTaskService: Shutting down[0m
[2m2025-08-18T04:53:33.158469Z[0m [[32m[1minfo     [0m] [1m[<main>] BackgroundTaskService: Waiting for task 'websocket-logger' to finish[0m
[2m2025-08-30T17:42:56.633657Z[0m [[32m[1minfo     [0m] [1m[<main>] Parlant server version 3.0.1[0m
[2m2025-08-30T17:42:56.634463Z[0m [[32m[1minfo     [0m] [1m[<main>] Using home directory 'C:\Users\usuario\parlant-data'[0m
[2m2025-08-30T17:42:56.637366Z[0m [[32m[1minfo     [0m] [1m[<main>] No external modules selected[0m
[2m2025-08-30T17:42:57.951339Z[0m [[32m[1minfo     [0m] [1m[<main>] Initialized OpenAIService[0m
