# ═══════════════════════════════════════════════════════════════════════════════
# ENTERPRISE EMPRESARIAL - ALERT RULES
# ═══════════════════════════════════════════════════════════════════════════════

groups:
  # ═══════════════════════════════════════════════════════════════════════════
  # N8N WORKFLOW ALERTS
  # ═══════════════════════════════════════════════════════════════════════════
  
  - name: n8n_alerts
    interval: 30s
    rules:
      - alert: N8nDown
        expr: up{job="n8n"} == 0
        for: 1m
        labels:
          severity: critical
          service: n8n
        annotations:
          summary: "n8n automation engine is down"
          description: "n8n has been unreachable for more than 1 minute."
          
      - alert: N8nHighExecutionTime
        expr: n8n_workflow_execution_duration_seconds > 30
        for: 5m
        labels:
          severity: warning
          service: n8n
        annotations:
          summary: "Workflow execution taking too long"
          description: "Workflow execution is taking more than 30 seconds."
          
      - alert: N8nHighErrorRate
        expr: rate(n8n_workflow_executions_total{status="error"}[5m]) > 0.1
        for: 10m
        labels:
          severity: warning
          service: n8n
        annotations:
          summary: "High workflow error rate"
          description: "More than 10% of workflows are failing."

  # ═══════════════════════════════════════════════════════════════════════════
  # DATABASE ALERTS
  # ═══════════════════════════════════════════════════════════════════════════
  
  - name: database_alerts
    interval: 30s
    rules:
      - alert: PostgresDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
          service: postgres
        annotations:
          summary: "PostgreSQL database is down"
          description: "PostgreSQL has been unreachable for more than 1 minute."
          
      - alert: PostgresHighConnections
        expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.8
        for: 5m
        labels:
          severity: warning
          service: postgres
        annotations:
          summary: "High PostgreSQL connection usage"
          description: "More than 80% of database connections in use."
          
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          service: redis
        annotations:
          summary: "Redis cache is down"
          description: "Redis has been unreachable for more than 1 minute."
          
      - alert: RedisHighMemory
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Redis memory usage high"
          description: "Redis is using more than 90% of available memory."

  # ═══════════════════════════════════════════════════════════════════════════
  # AI SERVICES ALERTS
  # ═══════════════════════════════════════════════════════════════════════════
  
  - name: ai_service_alerts
    interval: 30s
    rules:
      - alert: MCPServerDown
        expr: up{job="mcp-server"} == 0
        for: 2m
        labels:
          severity: critical
          service: mcp-server
        annotations:
          summary: "MCP Server is down"
          description: "MCP Server has been unreachable for more than 2 minutes."
          
      - alert: TemporalDown
        expr: up{job="temporal"} == 0
        for: 2m
        labels:
          severity: critical
          service: temporal
        annotations:
          summary: "Temporal orchestration is down"
          description: "Temporal has been unreachable for more than 2 minutes."
          
      - alert: AIHighLatency
        expr: histogram_quantile(0.95, rate(ai_request_duration_seconds_bucket[5m])) > 5
        for: 10m
        labels:
          severity: warning
          service: ai
        annotations:
          summary: "AI API latency is high"
          description: "95th percentile AI request latency is above 5 seconds."

  # ═══════════════════════════════════════════════════════════════════════════
  # BUSINESS METRICS ALERTS
  # ═══════════════════════════════════════════════════════════════════════════
  
  - name: business_alerts
    interval: 1m
    rules:
      - alert: NoLeadsReceivedIn1Hour
        expr: increase(leads_received_total[1h]) == 0
        for: 1h
        labels:
          severity: warning
          service: leads
        annotations:
          summary: "No leads received in the last hour"
          description: "The system has not received any new leads in the past hour during business hours."
          
      - alert: HighValueTransactionAlert
        expr: transaction_amount_usd > 10000
        for: 0s
        labels:
          severity: info
          service: finance
        annotations:
          summary: "High value transaction detected"
          description: "A transaction exceeding $10,000 was processed."
          
      - alert: TaskSLABreach
        expr: task_sla_breach_total > 0
        for: 5m
        labels:
          severity: warning
          service: operations
        annotations:
          summary: "Task SLA breach detected"
          description: "One or more tasks have breached their SLA."

  # ═══════════════════════════════════════════════════════════════════════════
  # INFRASTRUCTURE ALERTS
  # ═══════════════════════════════════════════════════════════════════════════
  
  - name: infrastructure_alerts
    interval: 15s
    rules:
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above 80% for more than 10 minutes."
          
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 10m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is above 85% for more than 10 minutes."
          
      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 15
        for: 5m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Disk space is running low"
          description: "Available disk space is below 15%."
          
      - alert: ContainerDown
        expr: absent(container_last_seen{name=~"enterprise-.*"})
        for: 5m
        labels:
          severity: critical
          service: docker
        annotations:
          summary: "Container is down"
          description: "An Enterprise container has been down for more than 5 minutes."
